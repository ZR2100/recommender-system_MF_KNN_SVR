{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPUOXaHuUYUj"
      },
      "source": [
        "#**Download The Dataset From Kaggle**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkxMDtVgUYkb",
        "outputId": "105484dc-030b-41dc-d00b-4b7bf69f8cfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Dataset URL: https://www.kaggle.com/datasets/shubhammehta21/movie-lens-small-latest-dataset\n",
            "License(s): unknown\n",
            "movie-lens-small-latest-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  movie-lens-small-latest-dataset.zip\n",
            "replace README.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)  # Force remount if already mounted\n",
        "!pip install kaggle\n",
        "!mkdir -p ~/.kaggle  # Use -p to avoid error if directory exists\n",
        "# Make sure to place your kaggle.json file in the specified path in your Google Drive\n",
        "!cp /content/drive/MyDrive/kaggle/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d shubhammehta21/movie-lens-small-latest-dataset --force  # Use --force to overwrite existing files\n",
        "!unzip -o movie-lens-small-latest-dataset.zip  # Use -o to overwrite existing files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrcEl1LYUbG7"
      },
      "source": [
        "#**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxqqsXMzS36n"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import xgboost as xgb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS7Qj7JBZ4fl"
      },
      "source": [
        "# **Load The Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-22tlROQZ4lm"
      },
      "outputs": [],
      "source": [
        "ratings = pd.read_csv('ratings.csv')\n",
        "movies = pd.read_csv('movies.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1FJoCnUqU08"
      },
      "source": [
        "#**Model Implementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEnhSXvVUL61"
      },
      "source": [
        "#**Encode movieId and userId**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-pfHRzNUOmb"
      },
      "outputs": [],
      "source": [
        "user_enc = LabelEncoder()\n",
        "ratings['user'] = user_enc.fit_transform(ratings['userId'].values)\n",
        "movie_enc = LabelEncoder()\n",
        "ratings['movie'] = movie_enc.fit_transform(ratings['movieId'].values)\n",
        "num_users = ratings['user'].nunique()\n",
        "num_movies = ratings['movie'].nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIMQ3SMFUQqt"
      },
      "source": [
        "#**Create item-user matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qi-DJP31UTQm"
      },
      "outputs": [],
      "source": [
        "Y = np.zeros((num_movies, num_users))\n",
        "for row in ratings.itertuples():\n",
        "    Y[row.movie, row.user] = row.rating\n",
        "\n",
        "R = (Y > 0).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBxgRpo_Ulk_"
      },
      "source": [
        "#**Normalize Ratings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nLg7QY9Ulqd"
      },
      "outputs": [],
      "source": [
        "def normalizeRatings(Y, R):\n",
        "    Ymean = np.sum(Y, axis=1) / np.sum(R, axis=1)\n",
        "    Ymean = Ymean.reshape(-1, 1)\n",
        "    Ynorm = (Y - Ymean) * R\n",
        "    return Ynorm, Ymean\n",
        "\n",
        "Ynorm, Ymean = normalizeRatings(Y, R)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Laj1Gme-UuH2"
      },
      "source": [
        "#**Train-Validation-Test Split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zsq0Xx7GUwqW"
      },
      "outputs": [],
      "source": [
        "train_indices, temp_indices = train_test_split(np.arange(num_users), test_size=0.4, random_state=42)\n",
        "val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
        "\n",
        "\n",
        "Y_train = Y[:, train_indices]\n",
        "R_train = R[:, train_indices]\n",
        "Y_val = Y[:, val_indices]\n",
        "R_val = R[:, val_indices]\n",
        "Y_test = Y[:, test_indices]\n",
        "R_test = R[:, test_indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLL5Hy5iU84W"
      },
      "source": [
        "#**For Consistent Results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjLbgA7vU89C"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xqFTwcPVA6l"
      },
      "source": [
        "#**Define Number Of Features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ni97Nx4iVBDK"
      },
      "outputs": [],
      "source": [
        "num_features = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvMFw9dDVLrP"
      },
      "source": [
        "#**Initial Parameters (W, X, b)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qHg-NcSVORo"
      },
      "outputs": [],
      "source": [
        "W = tf.Variable(tf.random.normal((num_users, num_features), dtype=tf.float64), name='W')\n",
        "X = tf.Variable(tf.random.normal((num_movies, num_features), dtype=tf.float64), name='X')\n",
        "b = tf.Variable(tf.random.normal((1, num_users), dtype=tf.float64), name='b')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi4ANpVqVWkE"
      },
      "source": [
        "#**Define Cost function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kv4N9Q2xVYXK"
      },
      "outputs": [],
      "source": [
        "def cost_func(X, W, b, Y, R, lambda_):\n",
        "    Y = np.nan_to_num(Y)\n",
        "    j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y) * R\n",
        "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n",
        "    return J"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri-tXVjpVebs"
      },
      "source": [
        "#**Instantiate The optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CQYgnJ7Vg-d"
      },
      "outputs": [],
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=1e-1)\n",
        "epochs = 200\n",
        "lambda_ = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJhT7Gt3Fb0j"
      },
      "source": [
        "#**KNN & DT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c23JVfaIAs0Q",
        "outputId": "bbb12274-30ad-4070-82d8-3b88fc04534f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNN RMSE: 1.1305569458931535, MSE: 1.2781590079072547, MAE: 0.896549606769004, Relative MAE: 0.25543482191137723\n",
            "__________________________________\n",
            "Decision Tree RMSE: 1.4545092597654767, MSE: 2.115597186743515, MAE: 1.1316111124567982, Relative MAE: 0.3224059001319848\n"
          ]
        }
      ],
      "source": [
        "Ymean = np.mean(Y, axis=1)\n",
        "\n",
        "user_ids_train, item_ids_train = np.where(R_train == 1)\n",
        "ratings_train = Y_train[R_train == 1]\n",
        "\n",
        "ratings_train_normalized = ratings_train - Ymean[item_ids_train]\n",
        "\n",
        "knn = KNeighborsRegressor(n_neighbors=5)\n",
        "knn.fit(np.column_stack((user_ids_train, item_ids_train)), ratings_train_normalized)\n",
        "\n",
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "dt.fit(np.column_stack((user_ids_train, item_ids_train)), ratings_train_normalized)\n",
        "\n",
        "user_ids_test, item_ids_test = np.where(R_test == 1)\n",
        "ratings_test = Y_test[R_test == 1]\n",
        "\n",
        "Y_pred_knn = knn.predict(np.column_stack((user_ids_test, item_ids_test))) + Ymean[item_ids_test]\n",
        "Y_pred_knn = np.clip(Y_pred_knn, 0.5, 5.0)\n",
        "\n",
        "Y_pred_knn_flat = Y_pred_knn.flatten()\n",
        "ratings_test_flat = ratings_test.flatten()\n",
        "\n",
        "rmse_knn = np.sqrt(mean_squared_error(ratings_test_flat, Y_pred_knn_flat))\n",
        "mse_knn = mean_squared_error(ratings_test_flat, Y_pred_knn_flat)\n",
        "mae_knn = mean_absolute_error(ratings_test_flat, Y_pred_knn_flat)\n",
        "r2_knn = r2_score(ratings_test_flat, Y_pred_knn_flat)\n",
        "relative_mae_knn = mae_knn / np.mean(ratings_test_flat)\n",
        "\n",
        "Y_pred_dt = dt.predict(np.column_stack((user_ids_test, item_ids_test))) + Ymean[item_ids_test]\n",
        "Y_pred_dt = np.clip(Y_pred_dt, 0.5, 5.0)\n",
        "\n",
        "Y_pred_dt_flat = Y_pred_dt.flatten()\n",
        "\n",
        "rmse_dt = np.sqrt(mean_squared_error(ratings_test_flat, Y_pred_dt_flat))\n",
        "mse_dt = mean_squared_error(ratings_test_flat, Y_pred_dt_flat)\n",
        "mae_dt = mean_absolute_error(ratings_test_flat, Y_pred_dt_flat)\n",
        "r2_dt = r2_score(ratings_test_flat, Y_pred_dt_flat)\n",
        "relative_mae_dt = mae_dt / np.mean(ratings_test_flat)\n",
        "\n",
        "print(f\"KNN RMSE: {rmse_knn}, MSE: {mse_knn}, MAE: {mae_knn}, Relative MAE: {relative_mae_knn}\")\n",
        "print(\"__________________________________\")\n",
        "print(f\"Decision Tree RMSE: {rmse_dt}, MSE: {mse_dt}, MAE: {mae_dt}, Relative MAE: {relative_mae_dt}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGteIAWGFkTE"
      },
      "source": [
        "#**SVR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSGs5MdPyCuV",
        "outputId": "a25494ab-d5c4-41c9-ca3b-d070902b6d97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVR Model RMSE: 1.0669038200834173, MSE: 1.1382837613085888, MAE: 0.8444090950877963,Relative MAE: 0.24057953424508205\n"
          ]
        }
      ],
      "source": [
        "Ymean = np.mean(Y, axis=1)\n",
        "\n",
        "user_ids_train, item_ids_train = np.where(R_train == 1)\n",
        "ratings_train = Y_train[R_train == 1]\n",
        "\n",
        "ratings_train_normalized = ratings_train - Ymean[item_ids_train]\n",
        "\n",
        "svr = SVR(kernel='rbf', C=1.0, epsilon=0.2)\n",
        "svr.fit(np.column_stack((user_ids_train, item_ids_train)), ratings_train_normalized)\n",
        "\n",
        "user_ids_test, item_ids_test = np.where(R_test == 1)\n",
        "ratings_test = Y_test[R_test == 1]\n",
        "\n",
        "Y_pred_svr = svr.predict(np.column_stack((user_ids_test, item_ids_test))) + Ymean[item_ids_test]\n",
        "Y_pred_svr = np.clip(Y_pred_svr, 0.5, 5.0)\n",
        "\n",
        "rmse_svr = np.sqrt(mean_squared_error(ratings_test, Y_pred_svr))\n",
        "mse_svr = mean_squared_error(ratings_test, Y_pred_svr)\n",
        "mae_svr = mean_absolute_error(ratings_test, Y_pred_svr)\n",
        "mean_actual_ratings = np.mean(ratings_test)\n",
        "relative_mae = mae_svr / mean_actual_ratings\n",
        "\n",
        "print(f\"SVR Model RMSE: {rmse_svr}, MSE: {mse_svr}, MAE: {mae_svr},Relative MAE: {relative_mae}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzFp4E_2VlIE"
      },
      "source": [
        "#**Training loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w20D01B5S4Bu",
        "outputId": "df1d2701-85aa-430b-fa32-a6ce60e20d69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss at epoch 20: 5673114.3\n",
            "Validation loss at epoch 20: 1037053.3\n",
            "_______________________________________________________________\n",
            "Training loss at epoch 40: 286796.8\n",
            "Validation loss at epoch 40: 216710.6\n",
            "_______________________________________________________________\n",
            "Training loss at epoch 60: 110854.0\n",
            "Validation loss at epoch 60: 91674.2\n",
            "_______________________________________________________________\n",
            "Training loss at epoch 80: 54378.4\n",
            "Validation loss at epoch 80: 44372.1\n",
            "_______________________________________________________________\n",
            "Training loss at epoch 100: 31172.3\n",
            "Validation loss at epoch 100: 24716.7\n",
            "_______________________________________________________________\n",
            "Training loss at epoch 120: 19957.1\n",
            "Validation loss at epoch 120: 15357.3\n",
            "_______________________________________________________________\n",
            "Training loss at epoch 140: 13910.6\n",
            "Validation loss at epoch 140: 10377.6\n",
            "_______________________________________________________________\n",
            "Training loss at epoch 160: 10421.3\n",
            "Validation loss at epoch 160: 7523.6\n",
            "_______________________________________________________________\n",
            "Training loss at epoch 180: 8314.0\n",
            "Validation loss at epoch 180: 5799.7\n",
            "_______________________________________________________________\n",
            "Training loss at epoch 200: 6997.0\n",
            "Validation loss at epoch 200: 4716.6\n",
            "_______________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "Ynorm, Ymean = normalizeRatings(Y, R)\n",
        "training_losses = []\n",
        "validation_losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    with tf.GradientTape() as tape:\n",
        "        cost_value = cost_func(X, W, b, Ynorm, R, lambda_)\n",
        "    grads = tape.gradient(cost_value, [X, W, b])\n",
        "    training_losses.append(cost_value.numpy())\n",
        "    optimizer.apply_gradients(zip(grads, [X, W, b]))\n",
        "    val_cost_value = cost_func(X, tf.gather(W, val_indices, axis=0), tf.gather(b, val_indices, axis=1), Ynorm[:, val_indices], R_val, lambda_)\n",
        "    validation_losses.append(val_cost_value.numpy())\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"Training loss at epoch {epoch+20}: {cost_value:0.1f}\")\n",
        "        print(f\"Validation loss at epoch {epoch+20}: {val_cost_value:0.1f}\")\n",
        "        print(\"_______________________________________________________________\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBMIqH7FVw9V"
      },
      "source": [
        "#**Make predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLfUYCzVVxGN"
      },
      "outputs": [],
      "source": [
        "p = np.matmul(X.numpy(), np.transpose(W.numpy())) + b.numpy()\n",
        "pm = p + Ymean\n",
        "pm = np.clip(pm, 0.5, 5.0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dk5NWEZRV2Bj"
      },
      "source": [
        "# **Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYXeOMr8V2LM",
        "outputId": "537aa961-1408-49f3-cb66-d394e75df4e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 0.088557551509485\n",
            "__________________________________\n",
            "MSE: 0.007842439929355089\n",
            "__________________________________\n",
            "MAE: 0.06425721929156199\n",
            "__________________________________\n",
            "R2 Score: 0.9925705810833888\n"
          ]
        }
      ],
      "source": [
        "Y_pred = pm[:, test_indices]\n",
        "Y_true = Y[:, test_indices]\n",
        "\n",
        "Y_pred_flat = Y_pred[R_test == 1]\n",
        "Y_true_flat = Y_true[R_test == 1]\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(Y_true_flat, Y_pred_flat))\n",
        "mse = mean_squared_error(Y_true_flat, Y_pred_flat)\n",
        "mae = mean_absolute_error(Y_true_flat, Y_pred_flat)\n",
        "r2 = r2_score(Y_true_flat, Y_pred_flat)\n",
        "\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(\"__________________________________\")\n",
        "print(f\"MSE: {mse}\")\n",
        "print(\"__________________________________\")\n",
        "print(f\"MAE: {mae}\")\n",
        "print(\"__________________________________\")\n",
        "print(f\"R2 Score: {r2}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RMSLTN5DiBi",
        "outputId": "383a367b-3698-46d3-bccf-8b47301dd48c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relative MAE: 0.09637277060766568\n"
          ]
        }
      ],
      "source": [
        "# Calculate baseline MAE\n",
        "baseline_predictions = np.tile(Ymean, (1, Y.shape[1]))\n",
        "baseline_predictions_flat = baseline_predictions[R == 1]\n",
        "baseline_mae = mean_absolute_error(Y[R == 1], baseline_predictions_flat)\n",
        "# Calculate model MAE\n",
        "model_mae = mean_absolute_error(Y_true_flat, Y_pred_flat)\n",
        "# Calculate relative MAE\n",
        "relative_mae = model_mae / baseline_mae\n",
        "\n",
        "\n",
        "print(f\"Relative MAE: {relative_mae}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sq36jJRW7gD"
      },
      "source": [
        "#**Plots**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnubPcfmV8kC"
      },
      "source": [
        "# **Training loss**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rm6dL6u4V-L8"
      },
      "outputs": [],
      "source": [
        "plt.plot(range(epochs), training_losses, label='Training Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss vs. Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrQJHALmWvNG"
      },
      "source": [
        "# **Training and validation loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2jPIJqaWrn7"
      },
      "outputs": [],
      "source": [
        "plt.plot(range(epochs), training_losses, label='Training Loss')\n",
        "plt.plot(range(epochs), validation_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss vs. Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ViUFIEaXCl9"
      },
      "source": [
        "#**Predicted vs. Actual Ratings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBNRfboUXICH"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(Y_true_flat, Y_pred_flat, alpha=0.5)\n",
        "plt.plot([min(Y_true_flat), max(Y_true_flat)], [min(Y_true_flat), max(Y_true_flat)], color='red', linestyle='--')\n",
        "plt.xlabel('Actual Ratings')\n",
        "plt.ylabel('Predicted Ratings')\n",
        "plt.title('Predicted vs. Actual Ratings')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9s-WSmbXPXH"
      },
      "source": [
        "#**Histogram Of Residuals**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvh2NjM3XSrG"
      },
      "outputs": [],
      "source": [
        "residuals = Y_true_flat - Y_pred_flat\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(residuals, bins=50, alpha=0.75)\n",
        "plt.xlabel('Residuals')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Residuals')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HyXEr5DXem3"
      },
      "source": [
        "#**Predicted vs. Actual Ratings for A Sample User**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFS8fqunXneT"
      },
      "outputs": [],
      "source": [
        "user_id = test_indices[0]  # any user in the test set\n",
        "\n",
        "actual_ratings = Y[:, user_id]\n",
        "predicted_ratings = pm[:, user_id]\n",
        "\n",
        "rated_indices = R[:, user_id] == 1\n",
        "actual_ratings = actual_ratings[rated_indices]\n",
        "predicted_ratings = predicted_ratings[rated_indices]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(actual_ratings, predicted_ratings, alpha=0.5)\n",
        "plt.plot([min(actual_ratings), max(actual_ratings)], [min(actual_ratings), max(actual_ratings)], color='red', linestyle='--')\n",
        "plt.xlabel('Actual Ratings')\n",
        "plt.ylabel('Predicted Ratings')\n",
        "plt.title(f'Predicted vs. Actual Ratings for User {user_id}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lk-SEwe1YYJU"
      },
      "source": [
        "#**Enhanced visualization for predicted and actual ratings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIO3Gid6YUwo"
      },
      "outputs": [],
      "source": [
        "user_id = test_indices[22]  # any user in the test set\n",
        "\n",
        "actual_ratings = Y[:, user_id]\n",
        "predicted_ratings = pm[:, user_id]\n",
        "\n",
        "rated_indices = R[:, user_id] == 1\n",
        "actual_ratings = actual_ratings[rated_indices]\n",
        "predicted_ratings = predicted_ratings[rated_indices]\n",
        "movie_ids = np.arange(len(Y))[rated_indices]\n",
        "\n",
        "data = pd.DataFrame({\n",
        "    'Movie ID': movie_ids,\n",
        "    'Actual Ratings': actual_ratings,\n",
        "    'Predicted Ratings': predicted_ratings\n",
        "})\n",
        "\n",
        "data_melted = data.melt(id_vars='Movie ID', value_vars=['Actual Ratings', 'Predicted Ratings'], var_name='Type', value_name='Rating')\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "sns.barplot(x='Movie ID', y='Rating', hue='Type', data=data_melted)\n",
        "\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "plt.xlabel('Movie ID')\n",
        "plt.ylabel('Ratings')\n",
        "plt.title(f'Actual vs. Predicted Ratings for User {user_id}')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFIzDDSKqdzN"
      },
      "source": [
        "#**Recommending Movies To The Random User From Test set**\n",
        "recommend the top 10 movies for a random user from the test set.\n",
        "\n",
        "The recommended movies are among the\n",
        "top-rated movies with at least 50 ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlRcQv3Y3ZRd"
      },
      "outputs": [],
      "source": [
        "random_user = np.random.choice(test_indices)\n",
        "user_ratings = pm[:, random_user]\n",
        "watched_movies = R[:, random_user] == 1\n",
        "unwatched_movies = np.where(watched_movies == 0)[0]\n",
        "\n",
        "movie_ratings = ratings.groupby('movieId').agg({'rating': ['mean', 'count']})\n",
        "movie_ratings.columns = ['mean_rating', 'count_rating']\n",
        "top_rated_movies = movie_ratings[movie_ratings['count_rating'] >= 50].sort_values(by='mean_rating', ascending=False).index\n",
        "\n",
        "recommended_movies = np.array([movie for movie in unwatched_movies if movie in top_rated_movies])\n",
        "top_10_recommendations = np.argsort(user_ratings[recommended_movies])[-10:][::-1]\n",
        "\n",
        "recommendations = pd.DataFrame({\n",
        "    'movieId': recommended_movies[top_10_recommendations],\n",
        "    'predicted_rating': user_ratings[recommended_movies][top_10_recommendations]\n",
        "})\n",
        "\n",
        "recommendations = recommendations.merge(movies, left_on='movieId', right_on='movieId')\n",
        "recommendations = recommendations.merge(movie_ratings, left_on='movieId', right_index=True)\n",
        "\n",
        "print(f\"Top 10 movie recommendations for user {random_user}:\")\n",
        "print(recommendations[['title', 'mean_rating', 'count_rating', 'predicted_rating']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjZa_vjB9498"
      },
      "source": [
        "# **Ploting the recommendations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AF1B7GbF8WSJ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='predicted_rating', y='title', data=recommendations, palette='viridis')\n",
        "plt.xlabel('Predicted Rating')\n",
        "plt.title(f'Top 10 Movie Recommendations for User {random_user}')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
